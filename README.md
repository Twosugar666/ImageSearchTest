# ImageSearch
## news
### 2024.1.11 -- 周四
1. 阅读了CLIP的原论文
### 2024.1.12 -- 周五
1. 调研“A Survey on Large Language Model based Autonomous Agents”并撰写笔记
2. 调研“A Survey on Multimodal Large Language Models”并撰写笔记
3. 还在看“AGENT AI:SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION”
### 2024.1.15 -- 周一
1. “AGENT AI:SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION”阅读完成
2. 尝试配置了langchain、bisheng、crewai等开源框架
### 2024.1.16 -- 周二
1. LLAVA以及MiniGPT模型进行了调研
2. “Video-LLaVA: Learning United Visual Representation by Alignment Before Projection ”阅读完成
3. 线上测试了video-llava，感觉效果可以
4. “InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4”阅读完成
5. 挑选了三个开源但是不同类别的数据集
   1. ScienceQA -- ScienceQA is a multimodal benchmark containing multiple choice questions with a diverse set of science topics.
   2. NoCaps -- The NoCaps dataset contains 15100 images with 166100 human-written captions for novel object image captioning.
   3. Flickr30k -- The Flickr30k dataset consists of 31k images collected from Flickr. Each image has five ground truth captions.
### 2024.1.17 -- 周三
1. 调研了Gemini pro发现其性能表现不是很好，计划还是先继续深入研究Video-llava
2. 阅读了LEGO的论文原文，发现暂时还没有进行开源，之后开源了再深入研究
3. 分别了解了三个数据集的特性即不同场景下应该用什么数据集进行测试
4. 配置了云主机，以及模型所需的软件包环境
## 模型及实验
## 实验结果
## HowToUse
## 教程
## 引用
## thanks
